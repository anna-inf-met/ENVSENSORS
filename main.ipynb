{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "main.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "177d1IBs9HapVeZR_I0DMPn2QlfcmL2Rk",
      "authorship_tag": "ABX9TyNmRd2nVH9KtzQxx+RXp9ul",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/anna-inf-met/ENVSENSORS/blob/anna_pytch2tf_port/main.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tCr_c87ek1_0"
      },
      "source": [
        "Temporarily using a notebook as \"main\" to test porting of individual .py files for convcnp, from pytorch to tensorflow, with cloud gpu compute as resource"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cLBJEdL0SV2d"
      },
      "source": [
        "Important reference for converting Pytorch to tensorflow - re code architecture\n",
        "\n",
        "https://towardsdatascience.com/model-sub-classing-and-custom-training-loop-from-scratch-in-tensorflow-2-cc1d4f10fb4e"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hzUfw2vnlEol",
        "outputId": "66b94bc8-d974-434e-eafd-03b9e2b45ec5"
      },
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Select the Runtime > \"Change runtime type\" menu to enable a GPU accelerator, ')\n",
        "  print('and then re-execute this cell.')\n",
        "else:\n",
        "  print(gpu_info)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Select the Runtime > \"Change runtime type\" menu to enable a GPU accelerator, \n",
            "and then re-execute this cell.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fbCltAqmlGu0",
        "outputId": "d79462eb-7fdb-4966-e9e9-2b522df0461f"
      },
      "source": [
        "from psutil import virtual_memory\n",
        "ram_gb = virtual_memory().total / 1e9\n",
        "print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n",
        "\n",
        "if ram_gb < 20:\n",
        "  print('To enable a high-RAM runtime, select the Runtime > \"Change runtime type\"')\n",
        "  print('menu, and then select High-RAM in the Runtime shape dropdown. Then, ')\n",
        "  print('re-execute this cell.')\n",
        "else:\n",
        "  print('You are using a high-RAM runtime!')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Your runtime has 13.6 gigabytes of available RAM\n",
            "\n",
            "To enable a high-RAM runtime, select the Runtime > \"Change runtime type\"\n",
            "menu, and then select High-RAM in the Runtime shape dropdown. Then, \n",
            "re-execute this cell.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sw8VTD3oCi35",
        "outputId": "cf081687-b756-41d9-a86d-bec9cfcdd448"
      },
      "source": [
        "\n",
        "# Set up google drive for data\n",
        "from google.colab import drive \n",
        "drive.mount('/content/gdrive', force_remount=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WyS5Q075EyVv"
      },
      "source": [
        "#import sys\n",
        "#sys.path.append('/content/gdrive/MyDrive/ENVSENSORS/Code_Port_PyTch_2_TF/neural_downscaling')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3qvNTp21utJ_",
        "outputId": "fa89518e-884e-463e-a946-ab87f1c32f0f"
      },
      "source": [
        "cd /content/drive/MyDrive/ENVSENSORS/Code_Port_PyTch_2_TF/\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/Bette Davis Eyes/ENVSENSORS/Code_Port_PyTch_2_TF\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w25aRY1jL-vU",
        "outputId": "674c3576-7efc-4450-bd6d-fb4320533a79"
      },
      "source": [
        "!python setup.py install"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "running install\n",
            "running bdist_egg\n",
            "running egg_info\n",
            "writing neural_downscaling.egg-info/PKG-INFO\n",
            "writing dependency_links to neural_downscaling.egg-info/dependency_links.txt\n",
            "writing top-level names to neural_downscaling.egg-info/top_level.txt\n",
            "reading manifest file 'neural_downscaling.egg-info/SOURCES.txt'\n",
            "writing manifest file 'neural_downscaling.egg-info/SOURCES.txt'\n",
            "installing library code to build/bdist.linux-x86_64/egg\n",
            "running install_lib\n",
            "running build_py\n",
            "copying neural_downscaling/data/data_loader.py -> build/lib/neural_downscaling/data\n",
            "creating build/bdist.linux-x86_64/egg\n",
            "creating build/bdist.linux-x86_64/egg/neural_downscaling\n",
            "creating build/bdist.linux-x86_64/egg/neural_downscaling/architectures\n",
            "copying build/lib/neural_downscaling/architectures/__init__.py -> build/bdist.linux-x86_64/egg/neural_downscaling/architectures\n",
            "copying build/lib/neural_downscaling/architectures/set_conv.py -> build/bdist.linux-x86_64/egg/neural_downscaling/architectures\n",
            "copying build/lib/neural_downscaling/architectures/mlp.py -> build/bdist.linux-x86_64/egg/neural_downscaling/architectures\n",
            "copying build/lib/neural_downscaling/architectures/cnn.py -> build/bdist.linux-x86_64/egg/neural_downscaling/architectures\n",
            "creating build/bdist.linux-x86_64/egg/neural_downscaling/data\n",
            "copying build/lib/neural_downscaling/data/__init__.py -> build/bdist.linux-x86_64/egg/neural_downscaling/data\n",
            "copying build/lib/neural_downscaling/data/data_loader.py -> build/bdist.linux-x86_64/egg/neural_downscaling/data\n",
            "creating build/bdist.linux-x86_64/egg/neural_downscaling/models\n",
            "copying build/lib/neural_downscaling/models/distributions.py -> build/bdist.linux-x86_64/egg/neural_downscaling/models\n",
            "copying build/lib/neural_downscaling/models/__init__.py -> build/bdist.linux-x86_64/egg/neural_downscaling/models\n",
            "copying build/lib/neural_downscaling/models/conditional_np.py -> build/bdist.linux-x86_64/egg/neural_downscaling/models\n",
            "copying build/lib/neural_downscaling/__init__.py -> build/bdist.linux-x86_64/egg/neural_downscaling\n",
            "byte-compiling build/bdist.linux-x86_64/egg/neural_downscaling/architectures/__init__.py to __init__.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/neural_downscaling/architectures/set_conv.py to set_conv.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/neural_downscaling/architectures/mlp.py to mlp.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/neural_downscaling/architectures/cnn.py to cnn.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/neural_downscaling/data/__init__.py to __init__.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/neural_downscaling/data/data_loader.py to data_loader.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/neural_downscaling/models/distributions.py to distributions.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/neural_downscaling/models/__init__.py to __init__.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/neural_downscaling/models/conditional_np.py to conditional_np.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/neural_downscaling/__init__.py to __init__.cpython-37.pyc\n",
            "creating build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying neural_downscaling.egg-info/PKG-INFO -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying neural_downscaling.egg-info/SOURCES.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying neural_downscaling.egg-info/dependency_links.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying neural_downscaling.egg-info/top_level.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "zip_safe flag not set; analyzing archive contents...\n",
            "creating 'dist/neural_downscaling-1.0-py3.7.egg' and adding 'build/bdist.linux-x86_64/egg' to it\n",
            "removing 'build/bdist.linux-x86_64/egg' (and everything under it)\n",
            "Processing neural_downscaling-1.0-py3.7.egg\n",
            "Removing /usr/local/lib/python3.7/dist-packages/neural_downscaling-1.0-py3.7.egg\n",
            "Copying neural_downscaling-1.0-py3.7.egg to /usr/local/lib/python3.7/dist-packages\n",
            "neural-downscaling 1.0 is already the active version in easy-install.pth\n",
            "\n",
            "Installed /usr/local/lib/python3.7/dist-packages/neural_downscaling-1.0-py3.7.egg\n",
            "Processing dependencies for neural-downscaling==1.0\n",
            "Finished processing dependencies for neural-downscaling==1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ePOqWQzKCleO"
      },
      "source": [
        "from neural_downscaling.models import convCNP, Gaussian\n",
        "from neural_downscaling.data import DownscalingDataset"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UYqHMVGILrby"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2QPFfdbraw8H"
      },
      "source": [
        "output_dist = Gaussian(n_variables=1)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q1ufillxX07G"
      },
      "source": [
        "model = convCNP(in_channels=25, output_dist=output_dist)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_XF3Lph9PHTJ"
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gFUKtwVyOtZY"
      },
      "source": [
        "raw_data_loaded = np.load('x_context.npy')\n",
        "elev_data = np.load('elev_value.npy')"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 633
        },
        "id": "n0qjPPMkm-do",
        "outputId": "2ad29556-f236-4ce7-faba-7729a648ffcc"
      },
      "source": [
        "dataset = DownscalingDataset()\n",
        "dists = dataset.dists"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-d46b9f1a068a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDownscalingDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdists\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdists\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/drive/My Drive/Bette Davis Eyes/ENVSENSORS/Code_Port_PyTch_2_TF/neural_downscaling/data/data_loader.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, base_dir, training)\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0;31m# Calculate dists and scale\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m         \u001b[0mdists\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_dists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx_target\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx_context\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m...\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx_context\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m...\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m         \u001b[0mx_scaler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMinMaxScaler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdists\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdists\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx_scaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdists\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdists\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/drive/My Drive/Bette Davis Eyes/ENVSENSORS/Code_Port_PyTch_2_TF/neural_downscaling/data/data_loader.py\u001b[0m in \u001b[0;36m_get_dists\u001b[0;34m(self, target_x, grid_x, grid_y)\u001b[0m\n\u001b[1;32m     79\u001b[0m             \u001b[0mdists\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mgrid_x\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mpoint\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrid_y\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mpoint\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m             \u001b[0;31m#total_grid_list.append(total_grid[count, :, :] = dists)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m             \u001b[0mtotal_grid\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdists\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m             \u001b[0mcount\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: 'tensorflow.python.framework.ops.EagerTensor' object does not support item assignment"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "InhjmQr1U5NF"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "j7CKmUxfSUcm",
        "outputId": "88d92c94-dbc1-4810-9792-e86b8f04fe96"
      },
      "source": [
        "model.build_graph(raw_data_loaded.shape, dists.shape ,elev_data.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-ee83cdc9ae7a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_data_loaded\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/neural_downscaling-1.0-py3.7.egg/neural_downscaling/models/conditional_np.py\u001b[0m in \u001b[0;36mbuild_graph\u001b[0;34m(self, raw_shape)\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mbuild_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraw_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mraw_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mconvCNP\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m: call() missing 2 required positional arguments: 'dists' and 'elev'"
          ]
        }
      ]
    }
  ]
}